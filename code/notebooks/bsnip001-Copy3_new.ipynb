{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from scipy.spatial import ConvexHull\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "plt.style.use('ggplot')\n",
    "import pickle\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_graphviz\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "%matplotlib inline\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAuc(X,y,test_size=0.25,max_depth=None,n_estimators=100,\n",
    "           minsplit=4,FPR=[],TPR=[],VERBOSE=False, USE_ONLY=None):\n",
    "    '''\n",
    "        get AUC given training data X, with target labels y\n",
    "    '''\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    CLASSIFIERS=[DecisionTreeClassifier(max_depth=max_depth, min_samples_split=minsplit,class_weight='balanced'),\n",
    "                RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                       max_depth=max_depth,min_samples_split=minsplit,class_weight='balanced'),\n",
    "                ExtraTreesClassifier(n_estimators=n_estimators,\n",
    "                                     max_depth=max_depth,min_samples_split=minsplit,class_weight='balanced'),\n",
    "                AdaBoostClassifier(n_estimators=n_estimators),\n",
    "                GradientBoostingClassifier(n_estimators=n_estimators,max_depth=max_depth),\n",
    "                svm.SVC(kernel='rbf',gamma='scale',class_weight='balanced',probability=True)]\n",
    "\n",
    "    if USE_ONLY is not None:\n",
    "        if isinstance(USE_ONLY, (list,)):\n",
    "            CLASSIFIERS=[CLASSIFIERS[i] for i in USE_ONLY]\n",
    "        if isinstance(USE_ONLY, (int,)):\n",
    "            CLASSIFIERS=CLASSIFIERS[USE_ONLY]\n",
    "\n",
    "    for clf in CLASSIFIERS:\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred=clf.predict_proba(X_test)\n",
    "        #print(X_test,y_pred)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test,y_pred[:,1], pos_label=1)\n",
    "        auc=metrics.auc(fpr, tpr)\n",
    "        if VERBOSE:\n",
    "            print(auc)\n",
    "\n",
    "        FPR=np.append(FPR,fpr)\n",
    "        TPR=np.append(TPR,tpr)\n",
    "    points=np.array([[a[0],a[1]] for a in zip(FPR,TPR)])\n",
    "    hull = ConvexHull(points)\n",
    "    x=np.argsort(points[hull.vertices,:][:,0])\n",
    "    auc=metrics.auc(points[hull.vertices,:][x,0],points[hull.vertices,:][x,1])\n",
    "    return auc,CLASSIFIERS\n",
    "\n",
    "\n",
    "def saveFIG(filename='tmp.pdf',AXIS=False):\n",
    "    '''\n",
    "        save fig for publication\n",
    "    '''\n",
    "    import pylab as plt\n",
    "    plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, \n",
    "            hspace = 0, wspace = 0)\n",
    "    plt.margins(0,0)\n",
    "    if not AXIS:\n",
    "        plt.gca().xaxis.set_major_locator(plt.NullLocator())\n",
    "        plt.gca().yaxis.set_major_locator(plt.NullLocator())\n",
    "    plt.savefig(filename,dpi=300, bbox_inches = 'tight',\n",
    "                pad_inches = 0,transparent=False) \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCoverage(model,verbose=True):\n",
    "    '''\n",
    "        return how many distinct items (questions)\n",
    "        are used in the model set.\n",
    "        This includes the set of questions being\n",
    "        covered by all forms that may be \n",
    "        generated by the model set\n",
    "    '''\n",
    "    FS=[]\n",
    "    for m in model:\n",
    "        for count in range(len(m.estimators_)):\n",
    "            clf=m.estimators_[count]\n",
    "            fs=clf.tree_.feature[clf.tree_.feature>0]\n",
    "            FS=np.array(list(set(np.append(FS,fs))))\n",
    "    if verbose:\n",
    "        print(\"Number of items used: \", FS.size)\n",
    "    return FS\n",
    "\n",
    "def getConfusion(X,y,test_size=0.25,max_depth=None,n_estimators=100,\n",
    "           minsplit=4,CONFUSION={},VERBOSE=False, USE_ONLY=None,target_names = None):\n",
    "    '''\n",
    "        get AUC given training data X, with target labels y\n",
    "    '''\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    CLASSIFIERS=[DecisionTreeClassifier(max_depth=max_depth, min_samples_split=minsplit),\n",
    "                RandomForestClassifier(n_estimators=n_estimators,class_weight='balanced',\n",
    "                                       max_depth=max_depth,min_samples_split=minsplit),\n",
    "                ExtraTreesClassifier(n_estimators=n_estimators,class_weight='balanced',\n",
    "                                     max_depth=max_depth,min_samples_split=minsplit),\n",
    "                AdaBoostClassifier(n_estimators=n_estimators),\n",
    "                GradientBoostingClassifier(n_estimators=n_estimators,max_depth=max_depth),\n",
    "                svm.SVC(kernel='rbf',gamma='scale',class_weight='balanced',probability=True)]\n",
    "\n",
    "    if USE_ONLY is not None:\n",
    "        if isinstance(USE_ONLY, (list,)):\n",
    "            CLASSIFIERS=[CLASSIFIERS[i] for i in USE_ONLY]\n",
    "        if isinstance(USE_ONLY, (int,)):\n",
    "            CLASSIFIERS=CLASSIFIERS[USE_ONLY]\n",
    "\n",
    "    for clf in CLASSIFIERS:\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred=clf.predict(X_test)\n",
    "        print(y_test,y_pred)\n",
    "        cmat=confusion_matrix(y_test, y_pred)\n",
    "        acc=accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        CONFUSION[clf]=cmat\n",
    "        \n",
    "        if VERBOSE:\n",
    "            print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "            print('Confusion MAtrix:\\n', cmat)\n",
    "            print(' ')\n",
    "            print('Accuracy:', acc)\n",
    "\n",
    "        \n",
    "    return CONFUSION,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Biotype</th>\n",
       "      <th>project</th>\n",
       "      <th>panss_p1</th>\n",
       "      <th>panss_p2</th>\n",
       "      <th>panss_p3</th>\n",
       "      <th>panss_p4</th>\n",
       "      <th>panss_p5</th>\n",
       "      <th>panss_p6</th>\n",
       "      <th>panss_p7</th>\n",
       "      <th>panss_n1</th>\n",
       "      <th>...</th>\n",
       "      <th>young_9</th>\n",
       "      <th>young_10</th>\n",
       "      <th>young_11</th>\n",
       "      <th>sfs_setotal</th>\n",
       "      <th>sfs_ictotal</th>\n",
       "      <th>sfs_ipcptotal</th>\n",
       "      <th>sfs_ipcctotal</th>\n",
       "      <th>sfs_retotal</th>\n",
       "      <th>sfs_prototal</th>\n",
       "      <th>sfs_oetotal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Biotype  project  panss_p1  panss_p2  panss_p3  panss_p4  \\\n",
       "subject_id                                                             \n",
       "1                 2        1       4.0       3.0       4.0       1.0   \n",
       "4                 3        1       3.0       1.0       3.0       1.0   \n",
       "17                2        1       2.0       2.0       2.0       1.0   \n",
       "53                2        1       4.0       3.0       5.0       2.0   \n",
       "73                2        1       6.0       5.0       6.0       4.0   \n",
       "\n",
       "            panss_p5  panss_p6  panss_p7  panss_n1  ...  young_9  young_10  \\\n",
       "subject_id                                          ...                      \n",
       "1                3.0       2.0       1.0       4.0  ...      0.0       1.0   \n",
       "4                2.0       2.0       1.0       3.0  ...      0.0       0.0   \n",
       "17               1.0       2.0       1.0       3.0  ...      0.0       0.0   \n",
       "53               1.0       3.0       1.0       5.0  ...      0.0       1.5   \n",
       "73               5.0       6.0       6.0       1.0  ...      2.0       1.0   \n",
       "\n",
       "            young_11  sfs_setotal  sfs_ictotal  sfs_ipcptotal  sfs_ipcctotal  \\\n",
       "subject_id                                                                     \n",
       "1                2.0          9.0          8.0           27.0            NaN   \n",
       "4                0.0          7.0          8.0           19.0            NaN   \n",
       "17               0.0         12.0          7.0            NaN           39.0   \n",
       "53               0.0         10.0          4.0           24.0           31.0   \n",
       "73               4.0          7.0          7.0           21.0           18.0   \n",
       "\n",
       "            sfs_retotal  sfs_prototal  sfs_oetotal  \n",
       "subject_id                                          \n",
       "1                  25.0          45.0          5.0  \n",
       "4                  13.0           9.0          4.0  \n",
       "17                 13.0           NaN          3.0  \n",
       "53                 10.0          17.0          0.0  \n",
       "73                 15.0          11.0         10.0  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('combined_bsnip.csv',index_col=0).drop('DSM',axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    646\n",
       "2    631\n",
       "1    630\n",
       "Name: Biotype, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 is HC\n",
    "df.Biotype.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=df[df['Biotype']==3]\n",
    "df=df.dropna()\n",
    "df0=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1557, 58)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df=df0[df0.Biotype.isin([1,5])]\n",
    "df=df0\n",
    "X=df.iloc[:,2:].values\n",
    "y=df.Biotype.values#.astype(str)\n",
    "y3=[(int(x)==3)+0 for x in y ]\n",
    "y1=[(int(x)==1)+0 for x in y ]\n",
    "y2=[(int(x)==2)+0 for x in y ]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_, X_test_, y_train_, y_test_ = train_test_split(X, y, test_size=0.2)\n",
    "y3=[(int(x)==3)+0 for x in y_train_ ]\n",
    "y1=[(int(x)==1)+0 for x in y_train_ ]\n",
    "y2=[(int(x)==2)+0 for x in y_train_ ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:03<00:00, 129.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.612899360604717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ACC=[]\n",
    "CLFh={}\n",
    "for run in tqdm(np.arange(500)):\n",
    "    auc,CLFS=getAuc(X_train_,y3,test_size=0.2,max_depth=10,n_estimators=2,\n",
    "               minsplit=2,VERBOSE=False, USE_ONLY=[2])\n",
    "    ACC=np.append(ACC,auc)\n",
    "    if auc > 0.55:\n",
    "        CLFh[auc]=CLFS\n",
    "#sns.distplot(ACC)\n",
    "print(np.median(ACC))\n",
    "CLFstar3=CLFh[np.array([k for k in CLFh.keys()]).max()][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:03<00:00, 133.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5100273474373924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ACC=[]\n",
    "CLFh={}\n",
    "for run in tqdm(np.arange(500)):\n",
    "    auc,CLFS=getAuc(X_train_,y1,test_size=0.2,max_depth=10,n_estimators=2,\n",
    "               minsplit=2,VERBOSE=False, USE_ONLY=[2])\n",
    "    ACC=np.append(ACC,auc)\n",
    "    if auc > 0.55:\n",
    "        CLFh[auc]=CLFS\n",
    "#sns.distplot(ACC)\n",
    "print(np.median(ACC))\n",
    "CLFstar1=CLFh[np.array([k for k in CLFh.keys()]).max()][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:03<00:00, 132.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5579501915708812\n"
     ]
    }
   ],
   "source": [
    "ACC=[]\n",
    "CLFh={}\n",
    "for run in tqdm(np.arange(500)):\n",
    "    auc,CLFS=getAuc(X_train_,y2,test_size=0.2,max_depth=10,n_estimators=2,\n",
    "               minsplit=2,VERBOSE=False, USE_ONLY=[2])\n",
    "    ACC=np.append(ACC,auc)\n",
    "    if auc > 0.55:\n",
    "        CLFh[auc]=CLFS\n",
    "#sns.distplot(ACC)\n",
    "print(np.median(ACC))\n",
    "CLFstar2=CLFh[np.array([k for k in CLFh.keys()]).max()][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312\n",
      "0.4230769230769231 [[0.32692308 0.34615385 0.32692308]\n",
      " [0.31578947 0.47368421 0.21052632]\n",
      " [0.3539823  0.17699115 0.46902655]]\n"
     ]
    }
   ],
   "source": [
    "y_pred3p=CLFstar3.predict_proba(X_test_)\n",
    "y_pred1p=CLFstar1.predict_proba(X_test_)\n",
    "y_pred2p=CLFstar2.predict_proba(X_test_)\n",
    "\n",
    "Y=[]\n",
    "a=1\n",
    "for (i,j,k) in zip(y_pred1p[:,1]**a,y_pred3p[:,1]**a,y_pred2p[:,1]**a):\n",
    "    idx=np.argmax([i,j,k])\n",
    "    #print(idx)\n",
    "    if idx == 0:\n",
    "        l=1\n",
    "        Y=np.append(Y,l)   \n",
    "        continue\n",
    "    if idx == 1:\n",
    "        l=3\n",
    "        Y=np.append(Y,l)   \n",
    "        continue\n",
    "    if idx == 2:\n",
    "        l=2\n",
    "        Y=np.append(Y,l)   \n",
    "        continue\n",
    "print(len(Y))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "ACC=accuracy_score(y_test_, Y)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "C=confusion_matrix(y_test_, Y)\n",
    "row_sums = C.sum(axis=1)\n",
    "C1 = C / row_sums[:, np.newaxis]\n",
    "print(ACC,C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "779\n",
      "0.0962772785622593 [[0.12015504 0.41860465 0.46124031]\n",
      " [0.43529412 0.07843137 0.48627451]\n",
      " [0.5        0.40977444 0.09022556]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in power\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "y_pred3p=CLFstar3.predict_proba(X_test)\n",
    "y_pred1p=CLFstar1.predict_proba(X_test)\n",
    "y_pred2p=CLFstar2.predict_proba(X_test)\n",
    "\n",
    "Y=[]\n",
    "a=-.3\n",
    "for (i,j,k) in zip(y_pred1p[:,1]**a,y_pred3p[:,1]**a,y_pred2p[:,1]**a):\n",
    "    idx=np.argmax([i,j,k])\n",
    "    #print(idx)\n",
    "    if idx == 0:\n",
    "        l=1\n",
    "        Y=np.append(Y,l)   \n",
    "        continue\n",
    "    if idx == 1:\n",
    "        l=3\n",
    "        Y=np.append(Y,l)   \n",
    "        continue\n",
    "    if idx == 2:\n",
    "        l=2\n",
    "        Y=np.append(Y,l)   \n",
    "        continue\n",
    "print(len(Y))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "ACC=accuracy_score(y_test, Y)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "C=confusion_matrix(y_test, Y)\n",
    "row_sums = C.sum(axis=1)\n",
    "C1 = C / row_sums[:, np.newaxis]\n",
    "print(ACC,C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.717948717948718 [[0.66666667 0.1875     0.14583333]\n",
      " [0.18918919 0.68468468 0.12612613]\n",
      " [0.15238095 0.04761905 0.8       ]]\n",
      "0.7147435897435898 [[0.73333333 0.1047619  0.16190476]\n",
      " [0.14150943 0.70754717 0.1509434 ]\n",
      " [0.22772277 0.06930693 0.7029703 ]]\n",
      "0.7019230769230769 [[0.69230769 0.19230769 0.11538462]\n",
      " [0.15116279 0.68604651 0.1627907 ]\n",
      " [0.17213115 0.10655738 0.72131148]]\n",
      "0.6826923076923077 [[0.67924528 0.16037736 0.16037736]\n",
      " [0.17021277 0.70212766 0.12765957]\n",
      " [0.1875     0.14285714 0.66964286]]\n",
      "0.6923076923076923 [[0.61061947 0.17699115 0.21238938]\n",
      " [0.11864407 0.73728814 0.1440678 ]\n",
      " [0.13580247 0.12345679 0.74074074]]\n",
      "0.7211538461538461 [[0.73636364 0.11818182 0.14545455]\n",
      " [0.15384615 0.73626374 0.10989011]\n",
      " [0.18018018 0.12612613 0.69369369]]\n",
      "0.6794871794871795 [[0.63366337 0.18811881 0.17821782]\n",
      " [0.15384615 0.68376068 0.16239316]\n",
      " [0.18085106 0.09574468 0.72340426]]\n",
      "0.7147435897435898 [[0.68571429 0.19047619 0.12380952]\n",
      " [0.17       0.71       0.12      ]\n",
      " [0.17757009 0.07476636 0.74766355]]\n",
      "0.7019230769230769 [[0.65168539 0.12359551 0.2247191 ]\n",
      " [0.12962963 0.74074074 0.12962963]\n",
      " [0.2        0.09565217 0.70434783]]\n",
      "0.6794871794871795 [[0.67326733 0.15841584 0.16831683]\n",
      " [0.20792079 0.65346535 0.13861386]\n",
      " [0.20909091 0.08181818 0.70909091]]\n",
      "0.6987179487179487 [[0.57894737 0.22105263 0.2       ]\n",
      " [0.16363636 0.71818182 0.11818182]\n",
      " [0.12149533 0.09345794 0.78504673]]\n",
      "0.6891025641025641 [[0.66990291 0.18446602 0.14563107]\n",
      " [0.14       0.71       0.15      ]\n",
      " [0.21100917 0.10091743 0.68807339]]\n",
      "0.6858974358974359 [[0.6635514  0.1682243  0.1682243 ]\n",
      " [0.19387755 0.65306122 0.15306122]\n",
      " [0.14018692 0.12149533 0.73831776]]\n",
      "0.6346153846153846 [[0.62037037 0.19444444 0.18518519]\n",
      " [0.21590909 0.59090909 0.19318182]\n",
      " [0.18965517 0.12931034 0.68103448]]\n",
      "0.6698717948717948 [[0.64705882 0.18627451 0.16666667]\n",
      " [0.17307692 0.66346154 0.16346154]\n",
      " [0.22641509 0.0754717  0.69811321]]\n",
      "0.7019230769230769 [[0.6969697  0.2020202  0.1010101 ]\n",
      " [0.15686275 0.68627451 0.15686275]\n",
      " [0.12612613 0.15315315 0.72072072]]\n",
      "0.6858974358974359 [[0.72268908 0.10084034 0.17647059]\n",
      " [0.20212766 0.62765957 0.17021277]\n",
      " [0.18181818 0.12121212 0.6969697 ]]\n",
      "0.7147435897435898 [[0.696      0.152      0.152     ]\n",
      " [0.12359551 0.7752809  0.1011236 ]\n",
      " [0.2244898  0.09183673 0.68367347]]\n",
      "0.717948717948718 [[0.70967742 0.09677419 0.19354839]\n",
      " [0.23076923 0.66346154 0.10576923]\n",
      " [0.16521739 0.06086957 0.77391304]]\n",
      "0.7307692307692307 [[0.72897196 0.17757009 0.09345794]\n",
      " [0.12745098 0.70588235 0.16666667]\n",
      " [0.13592233 0.10679612 0.75728155]]\n",
      "0.6858974358974359 [[0.65625    0.1875     0.15625   ]\n",
      " [0.1443299  0.70103093 0.15463918]\n",
      " [0.21848739 0.08403361 0.69747899]]\n",
      "0.7147435897435898 [[0.67567568 0.12612613 0.1981982 ]\n",
      " [0.10204082 0.75510204 0.14285714]\n",
      " [0.16504854 0.11650485 0.7184466 ]]\n",
      "0.6858974358974359 [[0.66055046 0.21100917 0.12844037]\n",
      " [0.14705882 0.67647059 0.17647059]\n",
      " [0.18811881 0.08910891 0.72277228]]\n",
      "0.6826923076923077 [[0.69672131 0.14754098 0.1557377 ]\n",
      " [0.15217391 0.63043478 0.2173913 ]\n",
      " [0.18367347 0.10204082 0.71428571]]\n",
      "0.6891025641025641 [[0.73148148 0.13888889 0.12962963]\n",
      " [0.14141414 0.66666667 0.19191919]\n",
      " [0.25714286 0.07619048 0.66666667]]\n",
      "0.6762820512820513 [[0.71153846 0.15384615 0.13461538]\n",
      " [0.13592233 0.62135922 0.24271845]\n",
      " [0.17142857 0.13333333 0.6952381 ]]\n",
      "0.6987179487179487 [[0.71559633 0.12844037 0.1559633 ]\n",
      " [0.11214953 0.71962617 0.1682243 ]\n",
      " [0.23958333 0.10416667 0.65625   ]]\n",
      "0.7083333333333334 [[0.66990291 0.17475728 0.15533981]\n",
      " [0.13084112 0.71028037 0.1588785 ]\n",
      " [0.18627451 0.06862745 0.74509804]]\n",
      "0.6955128205128205 [[0.68686869 0.15151515 0.16161616]\n",
      " [0.11881188 0.69306931 0.18811881]\n",
      " [0.17857143 0.11607143 0.70535714]]\n",
      "0.6858974358974359 [[0.64035088 0.21929825 0.14035088]\n",
      " [0.1875     0.65625    0.15625   ]\n",
      " [0.1372549  0.09803922 0.76470588]]\n",
      "0.6762820512820513 [[0.68421053 0.16842105 0.14736842]\n",
      " [0.17307692 0.65384615 0.17307692]\n",
      " [0.19469027 0.11504425 0.69026549]]\n",
      "0.6762820512820513 [[0.67619048 0.16190476 0.16190476]\n",
      " [0.19230769 0.64423077 0.16346154]\n",
      " [0.16504854 0.12621359 0.70873786]]\n",
      "0.6762820512820513 [[0.61864407 0.23728814 0.1440678 ]\n",
      " [0.13684211 0.67368421 0.18947368]\n",
      " [0.17171717 0.08080808 0.74747475]]\n",
      "0.6762820512820513 [[0.68376068 0.14529915 0.17094017]\n",
      " [0.1980198  0.64356436 0.15841584]\n",
      " [0.22340426 0.07446809 0.70212766]]\n",
      "0.7371794871794872 [[0.69230769 0.19230769 0.11538462]\n",
      " [0.06122449 0.78571429 0.15306122]\n",
      " [0.13636364 0.12727273 0.73636364]]\n",
      "0.717948717948718 [[0.7184466  0.09708738 0.18446602]\n",
      " [0.15151515 0.75757576 0.09090909]\n",
      " [0.22727273 0.09090909 0.68181818]]\n",
      "0.6891025641025641 [[0.66371681 0.17699115 0.15929204]\n",
      " [0.12       0.73       0.15      ]\n",
      " [0.18181818 0.14141414 0.67676768]]\n",
      "0.657051282051282 [[0.66990291 0.14563107 0.18446602]\n",
      " [0.1509434  0.62264151 0.22641509]\n",
      " [0.22330097 0.09708738 0.67961165]]\n",
      "0.6923076923076923 [[0.68686869 0.17171717 0.14141414]\n",
      " [0.17346939 0.67346939 0.15306122]\n",
      " [0.2        0.08695652 0.71304348]]\n",
      "0.7403846153846154 [[0.69724771 0.19266055 0.11009174]\n",
      " [0.09278351 0.75257732 0.15463918]\n",
      " [0.14150943 0.08490566 0.77358491]]\n",
      "0.7051282051282052 [[0.7        0.18       0.12      ]\n",
      " [0.19047619 0.65714286 0.15238095]\n",
      " [0.13084112 0.11214953 0.75700935]]\n",
      "0.6602564102564102 [[0.6952381  0.12380952 0.18095238]\n",
      " [0.20588235 0.61764706 0.17647059]\n",
      " [0.20952381 0.12380952 0.66666667]]\n",
      "0.6634615384615384 [[0.62385321 0.22018349 0.1559633 ]\n",
      " [0.21       0.65       0.14      ]\n",
      " [0.2038835  0.0776699  0.7184466 ]]\n",
      "0.6955128205128205 [[0.68269231 0.13461538 0.18269231]\n",
      " [0.15454545 0.71818182 0.12727273]\n",
      " [0.23469388 0.08163265 0.68367347]]\n",
      "0.6923076923076923 [[0.6728972  0.14953271 0.17757009]\n",
      " [0.20588235 0.66666667 0.12745098]\n",
      " [0.16504854 0.09708738 0.73786408]]\n",
      "0.7371794871794872 [[0.7311828  0.17204301 0.09677419]\n",
      " [0.11538462 0.72115385 0.16346154]\n",
      " [0.1826087  0.06086957 0.75652174]]\n",
      "0.6762820512820513 [[0.65625    0.19791667 0.14583333]\n",
      " [0.15909091 0.69318182 0.14772727]\n",
      " [0.1796875  0.140625   0.6796875 ]]\n",
      "0.6762820512820513 [[0.67021277 0.13829787 0.19148936]\n",
      " [0.16964286 0.66964286 0.16071429]\n",
      " [0.21698113 0.09433962 0.68867925]]\n",
      "0.7243589743589743 [[0.76470588 0.06862745 0.16666667]\n",
      " [0.18478261 0.68478261 0.13043478]\n",
      " [0.20338983 0.07627119 0.72033898]]\n",
      "0.6891025641025641 [[0.70103093 0.15463918 0.1443299 ]\n",
      " [0.16101695 0.6779661  0.16101695]\n",
      " [0.16494845 0.1443299  0.69072165]]\n",
      "0.7339743589743589 [[0.75789474 0.11578947 0.12631579]\n",
      " [0.20353982 0.67256637 0.12389381]\n",
      " [0.17307692 0.04807692 0.77884615]]\n",
      "0.7211538461538461 [[0.72631579 0.11578947 0.15789474]\n",
      " [0.19444444 0.68518519 0.12037037]\n",
      " [0.18348624 0.06422018 0.75229358]]\n",
      "0.7243589743589743 [[0.64835165 0.18681319 0.16483516]\n",
      " [0.1559633  0.75229358 0.09174312]\n",
      " [0.16964286 0.07142857 0.75892857]]\n",
      "0.7019230769230769 [[0.65168539 0.20224719 0.14606742]\n",
      " [0.11650485 0.72815534 0.15533981]\n",
      " [0.175      0.10833333 0.71666667]]\n",
      "0.6987179487179487 [[0.77083333 0.14583333 0.08333333]\n",
      " [0.12149533 0.71028037 0.1682243 ]\n",
      " [0.21100917 0.16513761 0.62385321]]\n",
      "0.6762820512820513 [[0.67619048 0.19047619 0.13333333]\n",
      " [0.10891089 0.69306931 0.1980198 ]\n",
      " [0.20754717 0.13207547 0.66037736]]\n",
      "0.7115384615384616 [[0.70833333 0.14583333 0.14583333]\n",
      " [0.15238095 0.72380952 0.12380952]\n",
      " [0.18018018 0.11711712 0.7027027 ]]\n",
      "0.6730769230769231 [[0.59375    0.1875     0.21875   ]\n",
      " [0.12244898 0.75510204 0.12244898]\n",
      " [0.21186441 0.11864407 0.66949153]]\n",
      "0.6698717948717948 [[0.6        0.18823529 0.21176471]\n",
      " [0.22123894 0.65486726 0.12389381]\n",
      " [0.18421053 0.07894737 0.73684211]]\n",
      "0.6923076923076923 [[0.7007874  0.14173228 0.15748031]\n",
      " [0.18478261 0.64130435 0.17391304]\n",
      " [0.1827957  0.08602151 0.7311828 ]]\n",
      "0.7275641025641025 [[0.75454545 0.15454545 0.09090909]\n",
      " [0.13402062 0.75257732 0.11340206]\n",
      " [0.16190476 0.16190476 0.67619048]]\n",
      "0.6826923076923077 [[0.68932039 0.16504854 0.14563107]\n",
      " [0.2037037  0.63888889 0.15740741]\n",
      " [0.18811881 0.08910891 0.72277228]]\n",
      "0.7147435897435898 [[0.67567568 0.16216216 0.16216216]\n",
      " [0.11827957 0.68817204 0.19354839]\n",
      " [0.12962963 0.09259259 0.77777778]]\n",
      "0.6794871794871795 [[0.67961165 0.18446602 0.13592233]\n",
      " [0.18367347 0.65306122 0.16326531]\n",
      " [0.22522523 0.07207207 0.7027027 ]]\n",
      "0.7051282051282052 [[0.74561404 0.11403509 0.14035088]\n",
      " [0.20212766 0.68085106 0.11702128]\n",
      " [0.18269231 0.13461538 0.68269231]]\n",
      "0.6826923076923077 [[0.66393443 0.19672131 0.13934426]\n",
      " [0.17525773 0.71134021 0.11340206]\n",
      " [0.22580645 0.09677419 0.67741935]]\n",
      "0.7083333333333334 [[0.64957265 0.17948718 0.17094017]\n",
      " [0.12765957 0.70212766 0.17021277]\n",
      " [0.13861386 0.07920792 0.78217822]]\n",
      "0.6506410256410257 [[0.65714286 0.15238095 0.19047619]\n",
      " [0.17       0.61       0.22      ]\n",
      " [0.21495327 0.10280374 0.68224299]]\n",
      "0.6923076923076923 [[0.64150943 0.21698113 0.14150943]\n",
      " [0.11403509 0.77192982 0.11403509]\n",
      " [0.27173913 0.07608696 0.65217391]]\n",
      "0.7115384615384616 [[0.67368421 0.10526316 0.22105263]\n",
      " [0.09565217 0.72173913 0.1826087 ]\n",
      " [0.17647059 0.08823529 0.73529412]]\n",
      "0.657051282051282 [[0.68686869 0.16161616 0.15151515]\n",
      " [0.20952381 0.64761905 0.14285714]\n",
      " [0.25       0.11111111 0.63888889]]\n",
      "0.6730769230769231 [[0.63157895 0.19298246 0.1754386 ]\n",
      " [0.17283951 0.65432099 0.17283951]\n",
      " [0.15384615 0.11965812 0.72649573]]\n",
      "0.7211538461538461 [[0.75       0.13       0.12      ]\n",
      " [0.13861386 0.68316832 0.17821782]\n",
      " [0.17117117 0.0990991  0.72972973]]\n",
      "0.7115384615384616 [[0.67961165 0.18446602 0.13592233]\n",
      " [0.13461538 0.68269231 0.18269231]\n",
      " [0.12380952 0.1047619  0.77142857]]\n",
      "0.7051282051282052 [[0.61956522 0.20652174 0.17391304]\n",
      " [0.13888889 0.74074074 0.12037037]\n",
      " [0.14285714 0.11607143 0.74107143]]\n",
      "0.7371794871794872 [[0.7745098  0.11764706 0.10784314]\n",
      " [0.17142857 0.6952381  0.13333333]\n",
      " [0.17142857 0.08571429 0.74285714]]\n",
      "0.7243589743589743 [[0.67272727 0.15454545 0.17272727]\n",
      " [0.12380952 0.76190476 0.11428571]\n",
      " [0.16494845 0.09278351 0.74226804]]\n",
      "0.717948717948718 [[0.67676768 0.18181818 0.14141414]\n",
      " [0.15929204 0.73451327 0.10619469]\n",
      " [0.16       0.1        0.74      ]]\n",
      "0.6762820512820513 [[0.67676768 0.21212121 0.11111111]\n",
      " [0.18478261 0.66304348 0.15217391]\n",
      " [0.23966942 0.07438017 0.68595041]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7051282051282052 [[0.7254902  0.17647059 0.09803922]\n",
      " [0.13793103 0.68965517 0.17241379]\n",
      " [0.19512195 0.10569106 0.69918699]]\n",
      "0.7467948717948718 [[0.71276596 0.17021277 0.11702128]\n",
      " [0.11214953 0.76635514 0.12149533]\n",
      " [0.14414414 0.0990991  0.75675676]]\n",
      "0.6826923076923077 [[0.62857143 0.19047619 0.18095238]\n",
      " [0.14705882 0.70588235 0.14705882]\n",
      " [0.2        0.08571429 0.71428571]]\n",
      "0.6858974358974359 [[0.64356436 0.1980198  0.15841584]\n",
      " [0.15       0.71       0.14      ]\n",
      " [0.18918919 0.10810811 0.7027027 ]]\n",
      "0.6987179487179487 [[0.6344086  0.13978495 0.22580645]\n",
      " [0.18446602 0.66990291 0.14563107]\n",
      " [0.12931034 0.09482759 0.77586207]]\n",
      "0.6762820512820513 [[0.71296296 0.12037037 0.16666667]\n",
      " [0.24705882 0.63529412 0.11764706]\n",
      " [0.17647059 0.1512605  0.67226891]]\n",
      "0.6538461538461539 [[0.57281553 0.2038835  0.22330097]\n",
      " [0.17924528 0.66981132 0.1509434 ]\n",
      " [0.17475728 0.10679612 0.7184466 ]]\n",
      "0.717948717948718 [[0.64210526 0.17894737 0.17894737]\n",
      " [0.1754386  0.71929825 0.10526316]\n",
      " [0.14563107 0.06796117 0.78640777]]\n",
      "0.6955128205128205 [[0.67326733 0.13861386 0.18811881]\n",
      " [0.16346154 0.66346154 0.17307692]\n",
      " [0.1588785  0.09345794 0.74766355]]\n",
      "0.7115384615384616 [[0.6875     0.17708333 0.13541667]\n",
      " [0.14141414 0.70707071 0.15151515]\n",
      " [0.17948718 0.08547009 0.73504274]]\n",
      "0.6987179487179487 [[0.65263158 0.16842105 0.17894737]\n",
      " [0.1588785  0.71028037 0.13084112]\n",
      " [0.18181818 0.09090909 0.72727273]]\n",
      "0.7147435897435898 [[0.72916667 0.125      0.14583333]\n",
      " [0.16504854 0.69902913 0.13592233]\n",
      " [0.17699115 0.10619469 0.71681416]]\n",
      "0.7275641025641025 [[0.6969697  0.18181818 0.12121212]\n",
      " [0.11       0.75       0.14      ]\n",
      " [0.17699115 0.08849558 0.73451327]]\n",
      "0.6794871794871795 [[0.68686869 0.19191919 0.12121212]\n",
      " [0.16513761 0.69724771 0.13761468]\n",
      " [0.25961538 0.08653846 0.65384615]]\n",
      "0.7275641025641025 [[0.67346939 0.14285714 0.18367347]\n",
      " [0.1509434  0.74528302 0.10377358]\n",
      " [0.16666667 0.07407407 0.75925926]]\n",
      "0.7307692307692307 [[0.69230769 0.11965812 0.18803419]\n",
      " [0.1122449  0.74489796 0.14285714]\n",
      " [0.13402062 0.10309278 0.7628866 ]]\n",
      "0.6923076923076923 [[0.65765766 0.1981982  0.14414414]\n",
      " [0.17475728 0.66990291 0.15533981]\n",
      " [0.16326531 0.08163265 0.75510204]]\n",
      "0.7051282051282052 [[0.68571429 0.15238095 0.16190476]\n",
      " [0.18446602 0.7184466  0.09708738]\n",
      " [0.24038462 0.04807692 0.71153846]]\n",
      "0.7115384615384616 [[0.68627451 0.17647059 0.1372549 ]\n",
      " [0.10752688 0.74193548 0.15053763]\n",
      " [0.17094017 0.11965812 0.70940171]]\n",
      "0.6923076923076923 [[0.65178571 0.1875     0.16071429]\n",
      " [0.12244898 0.70408163 0.17346939]\n",
      " [0.16666667 0.10784314 0.7254902 ]]\n",
      "0.7147435897435898 [[0.77659574 0.08510638 0.13829787]\n",
      " [0.18018018 0.63963964 0.18018018]\n",
      " [0.17757009 0.08411215 0.73831776]]\n"
     ]
    }
   ],
   "source": [
    "for runs in np.arange(100):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    y_pred3p=CLFstar3.predict_proba(X_test)\n",
    "    y_pred1p=CLFstar1.predict_proba(X_test)\n",
    "    y_pred2p=CLFstar2.predict_proba(X_test)\n",
    "\n",
    "    Y=[]\n",
    "    a=1\n",
    "    for (i,j,k) in zip(y_pred1p[:,1]**a,y_pred3p[:,1]**a,y_pred2p[:,1]**a):\n",
    "        idx=np.argmax([i,j,k])\n",
    "        #print(idx)\n",
    "        if idx == 0:\n",
    "            l=1\n",
    "            Y=np.append(Y,l)   \n",
    "            continue\n",
    "        if idx == 1:\n",
    "            l=3\n",
    "            Y=np.append(Y,l)   \n",
    "            continue\n",
    "        if idx == 2:\n",
    "            l=2\n",
    "            Y=np.append(Y,l)   \n",
    "            continue\n",
    "\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    ACC=accuracy_score(y_test, Y)\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    C=confusion_matrix(y_test, Y)\n",
    "    row_sums = C.sum(axis=1)\n",
    "    C1 = C / row_sums[:, np.newaxis]\n",
    "    print(ACC,C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:02<00:00, 171.11it/s]\n",
      "/home/ishanu/.local/lib/python3.7/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/ishanu/.local/lib/python3.7/site-packages/matplotlib/cbook/__init__.py:1402: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  ndim = x[:, None].ndim\n",
      "/home/ishanu/.local/lib/python3.7/site-packages/matplotlib/axes/_base.py:276: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  x = x[:, np.newaxis]\n",
      "/home/ishanu/.local/lib/python3.7/site-packages/matplotlib/axes/_base.py:278: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  y = y[:, np.newaxis]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe86ec4c128>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RUNS=500\n",
    "A=[]\n",
    "for run in tqdm(np.arange(RUNS)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    y_pred3=CLFstar3.predict(X_test)\n",
    "    y_pred1=CLFstar1.predict(X_test)\n",
    "    Y=[]\n",
    "    for (i,j) in zip(y_pred1,y_pred3):\n",
    "        if i==0 and j==1:\n",
    "            k=5\n",
    "        if i==1 and j==0:\n",
    "            k=1\n",
    "        if i==0 and j==0:\n",
    "            k=2\n",
    "        if i==1 and j==1:\n",
    "            k=1\n",
    "        Y=np.append(Y,k)   \n",
    "    A=np.append(A,accuracy_score(y_test, Y))\n",
    "sns.distplot(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [312, 1557]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-f575d309aaf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mACC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 263\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [312, 1557]"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "y_pred3=CLFstar3.predict(X)\n",
    "y_pred1=CLFstar1.predict(X)\n",
    "Y=[]\n",
    "for (i,j) in zip(y_pred1,y_pred3):\n",
    "    if i==0 and j==1:\n",
    "        k=3\n",
    "    if i==1 and j==0:\n",
    "        k=1\n",
    "    if i==0 and j==0:\n",
    "        k=2\n",
    "    if i==1 and j==1:\n",
    "        k=1\n",
    "    Y=np.append(Y,k)   \n",
    "ACC=accuracy_score(y_test, Y)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "C=confusion_matrix(y_test, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[116,   7,   5],\n",
       "       [ 12,  56,  12],\n",
       "       [ 16,   8,  77]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCoverage(model,verbose=True):\n",
    "    '''\n",
    "        return how many distinct items (questions)\n",
    "        are used in the model set.\n",
    "        This includes the set of questions being\n",
    "        covered by all forms that may be \n",
    "        generated by the model set\n",
    "    '''\n",
    "    FS=[]\n",
    "    for m in model:\n",
    "        for count in range(len(m.estimators_)):\n",
    "            clf=m.estimators_[count]\n",
    "            fs=clf.tree_.feature[clf.tree_.feature>0]\n",
    "            FS=np.array(list(set(np.append(FS,fs))))\n",
    "    if verbose:\n",
    "        print(\"Number of items used: \", FS.size)\n",
    "    return FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ExtraTreeClassifier' object has no attribute 'estimators_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-5b4df69988f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgetCoverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCLFstar1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-68-90d2edf3cd23>\u001b[0m in \u001b[0;36mgetCoverage\u001b[0;34m(model, verbose)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mFS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mclf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ExtraTreeClassifier' object has no attribute 'estimators_'"
     ]
    }
   ],
   "source": [
    "getCoverage(CLFstar1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=CLFstar1.estimators_[0]\n",
    "a=' '.join(list(A.tree_.feature.astype(str))).split('-2')\n",
    "b=[len(x.split()) for x in a if x != ' ']\n",
    "np.array(b).sum()*(10/2**9)\n",
    "#len(list(set(A.tree_.feature[A.tree_.feature>0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAvLen(clf):\n",
    "    s=0\n",
    "    for e in clf.estimators_:\n",
    "        a=' '.join(list(e.tree_.feature.astype(str))).split('-2')\n",
    "        b=[len(x.split()) for x in a if x != ' ']\n",
    "        s=s+np.array(b).sum()*(10/2**9)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.2421875"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAvLen(CLFstar1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.73828125"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAvLen(CLFstar5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.2265625"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAvLen(CLFstar2)+getAvLen(CLFstar5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawTrees(model):\n",
    "    '''\n",
    "        draw the estimators (trees)\n",
    "        in a single model\n",
    "    '''\n",
    "    N=len(model.estimators_)\n",
    "\n",
    "    for count in range(N):\n",
    "        estimator = model.estimators_[count]\n",
    "\n",
    "        export_graphviz(estimator, out_file='tmptree.dot', \n",
    "                        #feature_names = iris.feature_names,\n",
    "                        #class_names = iris.target_names,\n",
    "                        rounded = True, proportion = False, \n",
    "                        precision = 2, filled = True)\n",
    "\n",
    "        from subprocess import call\n",
    "        call(['dot', '-Tpng', 'tmptree.dot', '-o', 'tmptree'+str(count)+'.png', '-Gdpi=600'])\n",
    "        from IPython.display import Image\n",
    "        Image(filename = 'tmptree'+str(count)+'.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawTrees(CLFstar5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "from scipy.interpolate import interp1d\n",
    "auc_=[]\n",
    "ROC={}\n",
    "fpr_ = np.linspace(0, 1, num=20, endpoint=True)\n",
    "for run in np.arange(1000):\n",
    "    clf=CLFstar\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "    y_pred=clf.predict_proba(X_test)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test,y_pred[:,1], pos_label=1)\n",
    "    f = interp1d(fpr, tpr)\n",
    "    auc_=np.append(auc_,metrics.auc(fpr_, f(fpr_)))\n",
    "    ROC[metrics.auc(fpr, tpr)]={'fpr':fpr_,'tpr':f(fpr_)}\n",
    "sns.distplot(auc_)\n",
    "auc_.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
